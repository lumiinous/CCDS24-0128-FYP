{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748412a3-dc48-4ddb-b9c0-ab9fbad8a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('/openfhe-python/openfhe/')\n",
    "from openfhe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da154d09-dbcb-4984-aab2-5abe758862a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup OpenFHE CKKS context and generate keys\n",
    "def setup_openfhe():\n",
    "    params = CCParamsCKKSRNS()\n",
    "    params.SetScalingModSize(40)  # Set the scaling factor for CKKS\n",
    "    params.SetMultiplicativeDepth(3)  # Set the multiplicative depth\n",
    "    params.SetSecurityLevel(HEStd_128_classic)\n",
    "    #params.SetRingDim(2048)\n",
    "    params.SetScalingTechnique(FIXEDAUTO)\n",
    "    params.SetBatchSize(1024)\n",
    "    \n",
    "    cc = GenCryptoContext(params)  # Generate the CKKS context\n",
    "    cc.Enable(PKESchemeFeature.PKE)  # Enable public key encryption features\n",
    "    cc.Enable(PKESchemeFeature.KEYSWITCH)  # Enable key switching\n",
    "    cc.Enable(PKESchemeFeature.LEVELEDSHE)  # Enable leveled homomorphic encryption\n",
    "    cc.Enable(PKESchemeFeature.ADVANCEDSHE)  # Enable leveled homomorphic encryption\n",
    "    cc.Enable (PKESchemeFeature.MULTIPARTY)\n",
    "    print(\"Mod size: \",params.GetFirstModSize())\n",
    "    print(\"Ring Dim: \",params.GetRingDim())\n",
    "    return cc\n",
    "\n",
    "# Step 2: Encrypt input using CKKS\n",
    "def encrypt_input(cc, public_key, input_data):\n",
    "    # Create a CKKS packed plaintext from the input data\n",
    "    plaintext = cc.MakeCKKSPackedPlaintext(input_data)\n",
    "    # Encrypt the plaintext using the public key\n",
    "    ciphertext = cc.Encrypt(public_key, plaintext)\n",
    "    return ciphertext\n",
    "\n",
    "# Step 3: Decrypt ciphertext back to plaintext (with trimming and handling small imaginary parts)\n",
    "def decrypt_input(cc, kp1_secret_key, kp2_secret_key, ciphertext, original_size):\n",
    "    ciphertextPartial1 = cc.MultipartyDecryptLead([ciphertext], kp1_secret_key)\n",
    "    ciphertextPartial2 = cc.MultipartyDecryptMain([ciphertext], kp2_secret_key)\n",
    "    partialCiphertextVec = [ciphertextPartial1[0], ciphertextPartial2[0]]\n",
    "    decrypted_plaintext = cc.MultipartyDecryptFusion(partialCiphertextVec)\n",
    "    decrypted_values = decrypted_plaintext.GetCKKSPackedValue()\n",
    "    trimmed_decrypted_values = decrypted_values[:original_size]\n",
    "    real_decrypted_values = [np.real_if_close(value, tol=1e-9) for value in trimmed_decrypted_values]\n",
    "    float_decrypted_values = [float(np.real(value)) for value in real_decrypted_values]\n",
    "    return float_decrypted_values\n",
    "\n",
    "#key generation\n",
    "cc=setup_openfhe()\n",
    "\n",
    "# For Party A\n",
    "kp1 = cc.KeyGen()\n",
    "evalMultKey = cc.KeySwitchGen(kp1.secretKey, kp1.secretKey)\n",
    "cc.EvalSumKeyGen(kp1.secretKey)\n",
    "evalSumKeys = cc.GetEvalSumKeyMap(kp1.secretKey.GetKeyTag())\n",
    "cc.EvalAtIndexKeyGen(kp1.secretKey, [3,1,-1,-3])\n",
    "evalAtIndexKeys=cc.GetEvalAutomorphismKeyMap(kp1.secretKey.GetKeyTag())\n",
    "\n",
    "# For Party B\n",
    "kp2 = cc.MultipartyKeyGen(kp1.publicKey)\n",
    "evalMultKey2 = cc.MultiKeySwitchGen(kp2.secretKey, kp2.secretKey, evalMultKey)\n",
    "\n",
    "# Combine evaluation multiplication keys from both parties\n",
    "evalMultAB = cc.MultiAddEvalKeys(evalMultKey, evalMultKey2, kp2.publicKey.GetKeyTag())\n",
    "evalMultBAB = cc.MultiMultEvalKey(kp2.secretKey, evalMultAB, kp2.publicKey.GetKeyTag())\n",
    "\n",
    "# Summation keys for both parties\n",
    "evalSumKeysB = cc.MultiEvalSumKeyGen(kp2.secretKey, evalSumKeys, kp2.publicKey.GetKeyTag())\n",
    "evalSumKeysJoin = cc.MultiAddEvalSumKeys(evalSumKeys, evalSumKeysB, kp2.publicKey.GetKeyTag())\n",
    "cc.InsertEvalSumKey(evalSumKeysJoin)\n",
    "\n",
    "# Final evaluation multiplication keys from both parties\n",
    "evalMultAAB = cc.MultiMultEvalKey(kp1.secretKey, evalMultAB, kp2.publicKey.GetKeyTag())\n",
    "evalMultFinal = cc.MultiAddEvalMultKeys(evalMultAAB, evalMultBAB, evalMultAB.GetKeyTag())\n",
    "\n",
    "# Insert the final multiplication key\n",
    "cc.InsertEvalMultKey([evalMultFinal])\n",
    "evalAtIndexKeysB=cc.MultiEvalAtIndexKeyGen(kp2.secretKey, evalAtIndexKeys, [3,1,-1,-3], kp2.publicKey.GetKeyTag())\n",
    "evalAtIndexKeysJoin = cc.MultiAddEvalAutomorphismKeys(evalAtIndexKeys, evalAtIndexKeysB, kp2.publicKey.GetKeyTag())\n",
    "cc.InsertEvalSumKey(evalAtIndexKeysJoin)#its the same function?\n",
    "\n",
    "\n",
    "# Define two-party bootstrapping function\n",
    "def two_party_bootstrapping(ciphertext, partyA, partyB, cc):\n",
    "    # Prepare ciphertext for bootstrapping by stripping c0\n",
    "    if ciphertext.GetLevel() < 2:\n",
    "        return ciphertext\n",
    "\n",
    "    c1 = ciphertext.Clone()\n",
    "    c1.RemoveElement(0)\n",
    "    \n",
    "    # Generate a common random polynomial (a)\n",
    "    a = cc.IntMPBootRandomElementGen(partyB.publicKey)\n",
    "    \n",
    "    # Each party generates its own decryption share\n",
    "    share1 = cc.IntMPBootDecrypt(partyA.secretKey, c1, a)\n",
    "    share2 = cc.IntMPBootDecrypt(partyB.secretKey, c1, a)\n",
    "    \n",
    "    # Aggregate the decryption shares\n",
    "    aggregatedShares = cc.IntMPBootAdd([share1, share2])\n",
    "    \n",
    "    # Re-encrypt (bootstrap) the ciphertext\n",
    "    bootstrapped_ciphertext = cc.IntMPBootEncrypt(partyB.publicKey, aggregatedShares, a, ciphertext)\n",
    "    \n",
    "    return bootstrapped_ciphertext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b9c08-d189-4591-8d75-d8ca1dc317fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(73)\n",
    "\n",
    "# Define transformation to resize to 8x8 and convert to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset with the new transformation\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Subset the datasets to use only half of the data\n",
    "train_subset_indices = list(range(len(train_data)))  # Use the first half\n",
    "test_subset_indices = list(range(len(test_data)))  # Use the first half\n",
    "\n",
    "print(f\"Number of samples in the training subset: {len(train_subset_indices)}\")\n",
    "print(f\"Number of samples in the testing subset: {len(test_subset_indices)}\")\n",
    "\n",
    "train_data = torch.utils.data.Subset(train_data, train_subset_indices)\n",
    "test_data = torch.utils.data.Subset(test_data, test_subset_indices)\n",
    "\n",
    "def flatten_dataset(dataset):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    # Use tqdm to add a progress bar\n",
    "    for img, label in tqdm(dataset, desc=\"Processing Dataset\"):\n",
    "        # Flatten 8x8 image to 1D array and encrypt\n",
    "        inputs.append(img.view(-1).tolist())\n",
    "        labels.append([label])  # Encrypt label\n",
    "\n",
    "    return inputs, labels  # Return primitive Python lists\n",
    "\n",
    "# Flatten training and testing datasets with progress bars\n",
    "flattened_train_inputs, flattened_train_labels = flatten_dataset(train_data)\n",
    "flattened_test_inputs, flattened_test_labels = flatten_dataset(test_data)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Print example shapes\n",
    "# example_input = flattened_train_inputs[0]  # The first flattened input\n",
    "# example_label = flattened_train_labels[0]  # The corresponding label\n",
    "\n",
    "# # Print the example\n",
    "# print(\"Flattened Input (1D array):\", example_input)  # A list of 64 floats (8x8)\n",
    "# #print(\"Shape of Flattened Input:\", len(example_input))  # Length: 64\n",
    "# print(\"Label:\", example_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb60c4-68bf-40d2-bf61-888e4acda5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, hidden=64, output=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Use Conv1d after flattening the 2D image to 1D\n",
    "        self.conv1 = torch.nn.Conv1d(1, 1, kernel_size=7, stride=3, padding=0)\n",
    "        # Fully connected layer (from flattened feature map to hidden layer)\n",
    "        self.fc1 = torch.nn.Linear(260, 10)\n",
    "\n",
    "    # Forward pass through the network\n",
    "    def forward(self, x):\n",
    "        # Flatten the 2D image to 1D (batch_size, 1, 784)\n",
    "        x = x.view(x.size(0), 1, -1)  # Flatten to 1D with single channel\n",
    "        x = self.conv1(x)\n",
    "        # Apply square activation function (x * x)\n",
    "        x = x * x\n",
    "        # Flatten the tensor again for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 4 * 260)\n",
    "        x = self.fc1(x)\n",
    "        # Apply square activation function again\n",
    "        return x\n",
    "\n",
    "# Step 3: Define the training function\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=1):\n",
    "    start_time = time.time()  # Record start time\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()  # Clear the gradients\n",
    "            output = model(data)   # Forward pass\n",
    "            loss = criterion(output, target)  # Calculate loss\n",
    "            loss.backward()  # Backward pass (calculate gradients)\n",
    "            optimizer.step()  # Update weights\n",
    "            train_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "        # Calculate and print average loss per epoch\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print(f'Epoch: {epoch} \\tTraining Loss: {train_loss:.6f}')\n",
    "        end_time = time.time()  # Record end time\n",
    "        \n",
    "        # Calculate the total time taken\n",
    "        total_time = end_time - start_time\n",
    "    print(f\"Total time taken for training: {total_time:.2f} seconds\")\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b47987-dd26-4e6e-ad05-a25f0dd59616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
    "    loss_history = []  # Stores loss for each epoch\n",
    "    loss_rate = []  # Stores rate of loss decrease\n",
    "\n",
    "    start_time = time.time()  # Record training start time\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_loss = 0.0  # Track loss per epoch\n",
    "        \n",
    "        for images, labels in train_loader:  # Iterate through mini-batches\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)  # Compute average loss for the epoch\n",
    "        loss_history.append(avg_loss)  # Store loss\n",
    "\n",
    "        # Compute rate of loss decrease\n",
    "        if epoch > 1:\n",
    "            rate = loss_history[-2] - avg_loss\n",
    "            loss_rate.append(rate)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Loss = {avg_loss:.6f}\")\n",
    "\n",
    "    end_time = time.time()  # Record training end time\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "    # Plot the loss and rate of loss decrease\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Loss over epochs\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, n_epochs + 1), loss_history, marker='o', linestyle='-', label=\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Rate of loss decrease\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(2, n_epochs + 1), loss_rate, marker='o', linestyle='-', color='r', label=\"Rate of Loss Decrease\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Rate of Loss Decrease\")\n",
    "    plt.title(\"Rate of Loss Decrease Over Epochs\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Step 4: Initialize model, loss function, and optimizer\n",
    "model = ConvNet()  # Instantiate the model\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Loss function for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "# Step 5: Train the model and visualize loss trends\n",
    "model = train(model, train_loader, criterion, optimizer, n_epochs=10)\n",
    "\n",
    "# Step 6: Display the model architecture using torchsummary\n",
    "summary(model, input_size=(1, 28, 28))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccec2c7-ff9e-44e7-bf4a-5d7336e37a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    start_time = time.time()  # Record start time\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(len(target)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss/len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ' \n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "    end_time = time.time()  # Record end time\n",
    "    \n",
    "    # Calculate the total time taken\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total time taken for training: {total_time:.2f} seconds\")\n",
    "    \n",
    "test(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972faf34-da8f-4b7a-96ec-3c63694f5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to test the model on a single input\n",
    "def test_single_image(model, test_loader):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a single batch of test images using the next() function\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Select a single image and its label\n",
    "    img = images[0]\n",
    "    label = labels[0]\n",
    "    \n",
    "    # Display the input image\n",
    "    plt.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "    plt.title(f'Original Label: {label}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Add a batch dimension and pass it through the model\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    print(img[0][0][0])\n",
    "    print(img[0][0][1])\n",
    "    print(img[0][0][2])\n",
    "    print(img[0][0][3])\n",
    "    print(img[0][0][4])\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        output = model(img)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    # Get the predicted label (class with highest probability)\n",
    "    predicted_label = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "    print(f'Predicted Label: {predicted_label}')\n",
    "    print(f'Predicted Probabilities: {probabilities}')\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Test the model on a single image\n",
    "predicted_label = test_single_image(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06336cec-be23-403f-885a-b7ed6351eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights = model.conv1.weight.data\n",
    "conv1_bias = model.conv1.bias.data\n",
    "print(conv1_bias)\n",
    "# Print the weights of each filter (mask)\n",
    "print(\"Shape of conv1 weights:\", conv1_weights.shape)  # Should be [4, 1, 7, 7]\n",
    "for i, filter_weight in enumerate(conv1_weights):\n",
    "    print(f\"\\nFilter {i + 1} (Mask {i + 1}):\")\n",
    "    print(filter_weight.squeeze().numpy())  # Convert to numpy for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2723913-39c8-4439-a1bc-c78b0b6f7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enc_conv1d(enc_input,enc_kernel,enc_bias,input_length,kernel_length,stride):\n",
    "    output_length=(input_length-kernel_length)//stride+1\n",
    "    mask=cc.MakeCKKSPackedPlaintext([1])\n",
    "    init_result=[0*output_length]\n",
    "    final_result= encrypt_input(cc, kp2.publicKey, init_result)\n",
    "\n",
    "    for i in range (output_length):\n",
    "        result = cc.EvalInnerProduct(enc_input,enc_kernel,kernel_length)\n",
    "        result = cc.EvalAdd(result,enc_bias)\n",
    "        result =cc.EvalMult(mask,result)\n",
    "        final_result=cc.EvalAdd(final_result,result)\n",
    "        if i<output_length-1:\n",
    "            enc_input=cc.EvalRotate(enc_input,stride)\n",
    "            final_result=cc.EvalRotate(final_result,-1)\n",
    "\n",
    "    decrypted_result=decrypt_input(cc,kp1.secretKey, kp2.secretKey,final_result,output_length)\n",
    "    reverse_result=decrypted_result[::-1]\n",
    "    tensor_output = torch.tensor(reverse_result, dtype=torch.float32)\n",
    "    # Reshape the tensor to match Conv1d output structure\n",
    "    # Assume Batch Size = 1, Channels = 1, Sequence Length = len(data_list)\n",
    "    tensor_output = tensor_output.view(1, 1, -1)\n",
    "    return tensor_output\n",
    "\n",
    "#print(example_input)\n",
    "example_input=[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "kernel=[0.5, 0.5, 0.5]\n",
    "bias=[1.0]\n",
    "input_length=len(example_input)\n",
    "kernel_length=len(kernel)\n",
    "encrypted_input= encrypt_input(cc, kp2.publicKey, example_input)\n",
    "encrypted_kernel= encrypt_input(cc, kp2.publicKey, kernel)\n",
    "encrypted_bias= encrypt_input(cc, kp2.publicKey, bias)\n",
    "result=Enc_conv1d(encrypted_input,encrypted_kernel,encrypted_bias,input_length,kernel_length,1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba84949-e670-41c2-9dc5-23b88c854c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Partial_ConvNet():\n",
    "    def __init__(self, model, cc, public_key):\n",
    "        \n",
    "        super(Partial_ConvNet, self).__init__()  # Call the parent class's constructor\n",
    "        start_time = time.time()\n",
    "        # Encrypt weights and biases of conv1\n",
    "        self.enc_conv1_weights = encrypt_input(cc, public_key, model.conv1.weight.flatten().tolist())\n",
    "        self.conv1_bias = encrypt_input(cc, public_key, model.conv1.bias.data.flatten().tolist())\n",
    "        end_time = time.time()  # Record end time\n",
    "    \n",
    "        # Calculate the total time taken\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Total time taken for encrypting parameter: {total_time:.2f} seconds\")\n",
    "        # Store references to inputs\n",
    "        self.model = model\n",
    "        self.cc = cc\n",
    "        self.public_key = public_key\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=Enc_conv1d(x,self.enc_conv1_weights,self.conv1_bias,784,7,3)\n",
    "        # Apply square activation function (x * x)\n",
    "        x = x * x\n",
    "        # Flatten the tensor again for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 4 * 260)\n",
    "        x = self.model.fc1(x)\n",
    "        # Apply square activation function again\n",
    "        return x\n",
    "\n",
    "    def Enc_conv1d(enc_input,enc_kernel,enc_bias,input_length,kernel_length,stride):\n",
    "        output_length=(input_length-kernel_length)//stride+1\n",
    "        print(output_length)\n",
    "        mask=cc.MakeCKKSPackedPlaintext([1])\n",
    "        init_result=[0*output_length]\n",
    "        final_result= encrypt_input(cc, kp2.publicKey, init_result)\n",
    "    \n",
    "        for i in range (output_length):\n",
    "            result = cc.EvalInnerProduct(enc_input,enc_kernel,kernel_length)\n",
    "            result = cc.EvalAdd(result,enc_bias)\n",
    "            result =cc.EvalMult(mask,result)\n",
    "            final_result=cc.EvalAdd(final_result,result)\n",
    "            if i<output_length-1:\n",
    "                enc_input=cc.EvalRotate(enc_input,stride)\n",
    "                final_result=cc.EvalRotate(final_result,-1)\n",
    "                \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "        decrypted_result=decrypt_input(cc,kp1.secretKey, kp2.secretKey,final_result,output_length)\n",
    "        reverse_result=decrypted_result[::-1]\n",
    "        tensor_output = torch.tensor(reverse_result, dtype=torch.float32)\n",
    "        # Reshape the tensor to match Conv1d output structure\n",
    "        # Assume Batch Size = 1, Channels = 1, Sequence Length = len(data_list)\n",
    "        tensor_output = tensor_output.view(1, 1, -1)\n",
    "        return tensor_output\n",
    "\n",
    "Enc_ConvNet= Partial_ConvNet(model,cc,kp2.publicKey)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87bfe19-cc36-445f-8faf-683b56354343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_image_enc(test_loader):\n",
    "    # Set model to evaluation mode\n",
    "    \n",
    "    # Get a single batch of test images using the next() function\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Select a single image and its label\n",
    "    img = images[0]\n",
    "    label = labels[0]\n",
    "    \n",
    "    # Display the input image\n",
    "    plt.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "    plt.title(f'Original Label: {label}')\n",
    "    plt.show()\n",
    "    example_input=img.view(-1).tolist()\n",
    "    encrypted_input= encrypt_input(cc, kp2.publicKey, example_input)\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        output = Enc_ConvNet(encrypted_input)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    # Get the predicted label (class with highest probability)\n",
    "    predicted_label = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "    print(f'Predicted Label: {predicted_label}')\n",
    "    #print(f'Predicted Probabilities: {probabilities}')\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Test the model on a single image\n",
    "predicted_label = test_single_image_enc(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea9647-8dbe-45a7-9d20-0b72847eb461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_test_data(test_loader, cc, public_key):\n",
    "\n",
    "    encrypted_data = []\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        for i in range(images.size(0)):  # Iterate through each image in the batch\n",
    "            img = images[i]\n",
    "            label = labels[i]\n",
    "\n",
    "            # Flatten the image and encrypt\n",
    "            example_input = img.view(-1).tolist()\n",
    "            encrypted_input = encrypt_input(cc, public_key, example_input)\n",
    "            \n",
    "            # Append the encrypted image and original label to the list\n",
    "            encrypted_data.append((encrypted_input, label.item()))\n",
    "\n",
    "    return encrypted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d9c28-cd1b-4cb2-bd8d-4b6ce36ac98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_test_data(test_loader, cc, public_key):\n",
    "\n",
    "    start_time = time.time()  # Start timing\n",
    "    encrypted_data = []\n",
    "\n",
    "    print(\"Encrypting test data...\")\n",
    "    for images, labels in tqdm(test_loader, desc=\"Encryption Progress\"):\n",
    "        for i in range(images.size(0)):  # Iterate through each image in the batch\n",
    "            img = images[i]\n",
    "            label = labels[i]\n",
    "\n",
    "            # Flatten the image and encrypt\n",
    "            example_input = img.view(-1).tolist()\n",
    "            encrypted_input = encrypt_input(cc, public_key, example_input)\n",
    "            \n",
    "            # Append the encrypted image and original label to the list\n",
    "            encrypted_data.append((encrypted_input, label.item()))\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "    print(f\"Time to encrypt test data: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Total number of encrypted samples: {len(encrypted_data)}\")\n",
    "    return encrypted_data\n",
    "\n",
    "\n",
    "\n",
    "def test_encrypted_data(encrypted_data, model, cc):\n",
    "\n",
    "    start_time = time.time()  # Start timing\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0  # Initialize total samples counter\n",
    "\n",
    "    print(\"Testing encrypted data...\")\n",
    "    for enc_img, true_label in tqdm(encrypted_data, desc=\"Testing Progress\"):\n",
    "        total_samples += 1  # Increment total samples\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculations\n",
    "            output = model(enc_img)\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Get the predicted label\n",
    "        predicted_label = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        if predicted_label == true_label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "    print(f\"Time to test encrypted data: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Accuracy on Encrypted Data: {accuracy:.2f}% ({correct_predictions}/{total_samples})\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Encrypt all test cases\n",
    "encrypted_test_data = encrypt_test_data(test_loader, cc, kp2.publicKey)\n",
    "\n",
    "# Test the model on the encrypted data\n",
    "accuracy = test_encrypted_data(encrypted_test_data, Enc_ConvNet, cc)\n",
    "print(f\"Final Accuracy on Encrypted Test Dataset: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f258eaa-332b-4359-b983-16da7954e247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
